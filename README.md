
# Embedding vs Image-Based AI: A Comparative Fairness Study in Chest X-ray Analysis

## Dataset access:

Both the MIMIC-CXR and CheXpert datasets, in their image and vector embedding forms, are publicly available under respective data use agreements.

MIMIC-CXR image  dataset is available at: https://physionet.org/content/mimic-cxr/2.0.0/

MIMIC-CXR embeddings  dataset is available at: https://physionet.org/content/image-embeddings-mimic-cxr/1.0/

CheXpert image dataset is available at: https://stanfordmlgroup.github.io/competitions/chexpert/

CheXpert embeddings dataset can be requested by filling out the [CXR Foundation Access Form](https://docs.google.com/forms/d/e/1FAIpQLSek0P-JSwSfonIiZJlz7gOTbL0lugsDug0FUnMhS1zVzpEKlg/viewform) from the authors of the CXR foundation model.

Access to both datasets requires user registration and the signing of a data use agreement. Only the MIMIC-CXR dataset requires the completion of an additional credentialing process. After following these procedures, the MIMIC-CXR data is available through PhysioNet (https://physionet.org/). The race/ethnicities and insurance type of the patients are not provided directly with the download of the MIMIC-CXR dataset. However, this data is available through merging the patient IDs in MIMIC-CXR with subject IDs in MIMIC-IV (https://physionet.org/content/mimiciv/0.4/) datasets, using the patient and admissions tables. Access to MIMIC-IV requires a similar procedure as MIMIC-CXR and the same credentialing process is applicable for both datasets. 

--------------------------------------------------------------------------------------------------
## Reproducing the results:

### Model Configuration
This part uses YAML configuration files located in the `./Training and evalaution/configs` directory to handle training, testing, and inference. Update the paths and parameters in these `.yaml` files to match your setup before execution. Model Configuration files are located in `./Training and evalaution/configs` configs directory under CXR_Emb/Training and evalaution  folder. 

#### Training
To train the model, use the following command. Replace ***.yaml with the name of your specific configuration file, and execute for different seeds. The seed numbers we used are [19,31,38,47,77]

```bash
`python main.py fit -c ./configs/***_config.yaml `

```

`***_config.yaml` should be replaced with actual config file name.

#### Testing
After training, the model can be tested  by specifying the path to the saved checkpoint and the configuration file used for training:

```bash
`python main.py test -c ./configs/***_config.yaml --ckpt_path ./path_to_saved_checkpoint `
```
Use the same YAML config used during training.



#### üîÑ About `prediction_on`

The `prediction_on` setting (in config) select which split (`train`, `val`, or `test`) the `predict` command runs on. It save prediction and will save them in the result folder:

| Value   | Files Saved                                     |
|---------|-------------------------------------------------|
| `train` | `probabilities_train.npy`, `labels_train.npy`   |
| `val`   | `probabilities_val.npy`, `labels_val.npy`       |
| `test`  | `probabilities_test.npy`, `labels_test.npy`     |

Make sure `save_probabilities_path` is set to enable saving.

You can override it on the CLI:

```bash
python main.py predict -c ./configs/your_config.yaml --ckpt_path ./path_to_checkpoint.ckpt
```

#### ‚öôÔ∏è Notes

- Use `ConcatDataset` to train across MIMIC + CheXpert.
- Adjust `batch_size`, `num_workers`, and `transform` as needed.
- `prediction_on` determines the split used for prediction and what files are saved.

## üìà Inference / Prediction

Run inference and optionally save probabilities + labels:

```bash
python main.py predict -c ./configs/***r_config.yaml --ckpt_path ./path_to_checkpoint.ckpt
```

#### Fairness analysis

The Fairness analysis is available in the `/Fairness/` directory. This directory includes six subfolders, each corresponding to a different dataset variant. For each scenario, we calculate the True Positive Rate (FPR) GAP across multiple random seeds, compute the average TPR GAP over five runs with 95% confidence intervals, and visualize the results using the `TPR_Disparities_**.ipynb` notebook, where `**` should be replaced with the relevant dataset name (e.g., `MIMIC_CXR` for the MIMIC dataset).

--------------------------------------------------------------------------------------------------
### Final remark:
 We are not able to share the trained model and the true label and predicted label CSV files of the test set due to the data-sharing agreement. However, we have provided the random seed, and the code. Then, the true label and predicted label CSV files and trained models can be generated by users who have downloaded the data from the original source following the procedure that is described in the ‚ÄúData access‚Äù session.



